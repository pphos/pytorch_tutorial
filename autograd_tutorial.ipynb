{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autograd_tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIdETBdjFLvQ5/EJpn6mRf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pphos/pytorch_tutorial/blob/master/autograd_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufbbff5S-ZF3",
        "colab_type": "text"
      },
      "source": [
        "# Autograd: Automatic Differentiaion\n",
        "\n",
        "PyTorchのすべてのニューラルネットワークの中心にあるものがautogradパッケージです.\n",
        "最初にこれを簡単にみて, ニューラルネットワークの訓練をしてみましょう！\n",
        "\n",
        "autogradパッケージは, テンソル上のすべての演算に対して自動微分を提供します.\n",
        "autogradはDefine-by-runフレームワークで, コードの実行方法によって逆伝搬が定義され, 各イテレーションごとに異なるものを使用できます.\n",
        "\n",
        "いくつかの例を挙げて, これをより簡単な言葉で見ていきましょう\n",
        "\n",
        "## Tensor\n",
        "`torch.Tensor`はパッケージの中心クラスです.\n",
        "`.require_grad`属性を`True`に設定すると, それに対するすべての操作を追跡し始めます.\n",
        "計算が終了したら`.backward()`を呼び出して, すべての勾配を自動的に計算させることができます.\n",
        "このテンソルの勾配は`.grad`属性に蓄積されます.\n",
        "\n",
        "テンソルが履歴を追跡しないようにするには, `detach()`を呼び出して計算履歴からテンソルを切り離し, 将来の計算が追跡されないようにします.\n",
        "\n",
        "履歴を追跡しないようにするためには, コードブロックを`torch.no_grad():`で囲むことでもできます.\n",
        "モデルが`requires_grad=True`で学習可能なパラメータを持っていても,\n",
        "勾配が必要ない場合があるため, モデルを評価する際に便利です.\n",
        "\n",
        "`autograd`の実装には`Function`というもう一つの重要なクラスがあります.\n",
        "`Tensor`と`Function`は相互に接続されており, 計算の完全な履歴をエンコードする非周期グラフを構築します.\n",
        "\n",
        "各テンソルは, テンソルを作成した関数を参照する`.grad_fn`属性を持っています.\n",
        "微分を計算したい場合は, テンソルに対して`.backward()`を呼び出すことができます.\n",
        "\n",
        "テンソルがスカラ(つまり1つの要素のデータを保持している)であれば, backward()に引数を指定する必要はありませんが, 要素数が多い場合は, 形状が一致するテンソルである勾配の引数を指定する必要があります.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9XIiOA-_hWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKgn7DuQDN1R",
        "colab_type": "text"
      },
      "source": [
        "テンソルを作成し, `requires_grad=True`を設定して, テンソルで計算を追跡します."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTcovk10DY1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2940f39e-32eb-4ecc-de60-a7fe72956631"
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeaMzjrJDeDG",
        "colab_type": "text"
      },
      "source": [
        "テンソルの操作を行います:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6_oJHGFDjeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2568b35f-063e-47fc-9f61-edfb0bdaeea9"
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsEPCMoMDmeF",
        "colab_type": "text"
      },
      "source": [
        "`y`は操作の結果として作成されたので, `grad_fn` があります."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRdKMxzFDvqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f7fcfe5-e7a7-4f1e-e13c-0e841099a8e3"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7f71a6fdf588>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alCTt2rWDw8l",
        "colab_type": "text"
      },
      "source": [
        "`y`でされに操作を行います"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogLk1oOaD2PV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d99bf8fe-0c70-4193-8d31-1f58cb44e368"
      },
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z, out)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l05jyidTD34d",
        "colab_type": "text"
      },
      "source": [
        "`.requires_grad_(...)`は, 既存のTensorの`requires_grad`フラグを代わりに変更します.\n",
        "入力フラグが与えられていない場合のデフォルトは`False`です."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztxyJGLNEZwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5f3046c6-d633-4be9-91b0-4e652ae01ba7"
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "<SumBackward0 object at 0x7f71a6fdf080>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRxxOwX1E-03",
        "colab_type": "text"
      },
      "source": [
        "# Gradients\n",
        "ここで逆伝搬をしてみましょう.\n",
        "`out`はスカラを1つ含むので, `out.backward()`は`out.backward(torch.tensor(1))`と等価です."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CNAiS6JFdkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le4tC2XJFfZi",
        "colab_type": "text"
      },
      "source": [
        "勾配 d(out)/dxを表示しましょう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWfZ5JigFrUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c2fb8e28-44ac-449f-9330-7ad30145071e"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho3JgS5AFtZx",
        "colab_type": "text"
      },
      "source": [
        "各要素が4.5である行列が表示されるはずです.\n",
        "このテンソルを\"$o$\"と呼びましょう.\n",
        "\n",
        "現在$o$は以下の値を持っています.\n",
        "\n",
        "$o = \\frac{1}{4}\\sum_i z_i$, $z_i = 3(x_i +2)^2$ $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
        "\n",
        "それゆえに$o$の各要素の微分は以下のようになります.\n",
        "\n",
        "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i + 2)$\n",
        "\n",
        "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YSShQHoHn1f",
        "colab_type": "text"
      },
      "source": [
        "autogradではクレイジーなことがたくさんできます."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lXwOAB3H4BS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61a9fbd6-a578-40a8-a868-c6b05c840dd1"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "  y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  -73.8176, -1202.9667,   136.7958], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx37H5zoIS3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05d95380-5ea4-425a-ccc2-6788ab090360"
      },
      "source": [
        "gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUIjrDY_IsX8",
        "colab_type": "text"
      },
      "source": [
        "`requires_grad=True`の場合は, コードブロックを`torch.no_grad()`でラップすることで, テンソル上でautogradが履歴を追跡しないようにすることもできます."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMyaIFxAJYuE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f05d1373-778b-4442-e568-2f0646640e67"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "  print((x ** 2).requires_grad)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}