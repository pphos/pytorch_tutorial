{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network_tutorial.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjL7+oC1CKlV+Y1lDSiOYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pphos/pytorch_tutorial/blob/master/neural_network_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsqWsq4DA7Ff",
        "colab_type": "text"
      },
      "source": [
        "# NEURAL NETWORKS\n",
        "ニューラルネットワークは`torch.nn`パッケージを用いて構築することができます.\n",
        "\n",
        "`nn.Module`にはレイヤーと, 出力を返す`forward(input)`メソッドがあります.\n",
        "\n",
        "ニューラルネットワークの典型的な学習手順は次の通りです.\n",
        "\n",
        "- 学習可能なパラメータを持つニューラルネットワークを定義する\n",
        "- 入力データセットを繰り返し処理する\n",
        "- ネットワークを介して入力を処理する\n",
        "- 損失を計算する (損失誤差がどれだけ小さく正解に近いかを計算する)\n",
        "- 勾配をネットワークに逆伝搬させる\n",
        "- ネットワークの重みを更新する:\n",
        "\n",
        " `weight = wehght - learning_rate * gradient`\n",
        "\n",
        "## Define the network\n",
        "\n",
        "ネットワークを定義してみよう:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyd-mg2GCQqY",
        "colab_type": "code",
        "outputId": "7b6577cf-abf5-4867-f3f0-31a32a142c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "    # kernel\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    # an affine operation: y = Wx + b\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Max pooling over a (2, 2) window\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "    # If the size is a square you can only specify a single number\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    return num_features\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaJ5auuD2MW",
        "colab_type": "text"
      },
      "source": [
        "`forward`関数を定義するだけで, 勾配の計算を行う`backward`関数は`autograd`により自動的に定義されます. `forward`関数では, Tensor演算のいずれかを用いることができます.\n",
        "\n",
        "学習可能なモデルのパラメータは`net.parameters()`によって返されます."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE6HJNlAEMOr",
        "colab_type": "code",
        "outputId": "1dbb3ae5-b0b7-43f9-bd6d-34d1ab7e9fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8tIGDFdEU_S",
        "colab_type": "text"
      },
      "source": [
        "32x32のランダムな入力を試してみましょう.\n",
        "\n",
        "Note:\n",
        "このネットワーク(LeNet)に期待される入力サイズは32x32です. MNISTデータセットをLeNetに適用するためには, データセットの画像を32x32にリサイズする必要があります."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjl5dkqKEjQc",
        "colab_type": "code",
        "outputId": "f39b44b4-fefa-4fec-a480-81294694dfc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0512, -0.0822,  0.0266, -0.0203, -0.1145,  0.0082, -0.0506,  0.0111,\n",
            "          0.0776,  0.0218]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3DBMYzsEqqw",
        "colab_type": "text"
      },
      "source": [
        "全てのパラメータとランダムな勾配を持つ逆伝搬の勾配のバッファを0にします."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgYk2mB8E0_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hyh8BX9CE9Zf",
        "colab_type": "text"
      },
      "source": [
        "### Note\n",
        "``torch.nn``はミニバッチ学習のみをサポートしています.\n",
        "``torch.nn``パッケージ全体では, サンプルのミニバッチ入力のみをサポートしており, 1サンプルの入力はサポートしていません.\n",
        "\n",
        "先に進む前に、これまでの内容をまとめてみましょう.\n",
        "\n",
        "Recap:\n",
        "- `torch.Tensor` - 多次元配列で``backward()``のような自動微分をサポートしています. また, テンソルに関連した勾配も保持します.\n",
        "- `nn.Module` - ニューラルネットワークモジュールおよびパラメータをカプセル化する便利な手段であり, GPUへの移動, エクスポート, ロードなどのヘルパがあります.\n",
        "- `nn.Parameter` - Tensorの一種で, `Module`に属性として代入すると自動的にパラメータとして登録されます.\n",
        "- `autograd.Function` - 自動微分の順伝搬および逆伝搬の定義を実装します.\n",
        "すべての`Tensor`操作は少なくとも一るの`Function`ノードを生成し, そのノートは`Tensor`を生成した関数に接続し, その履歴をエンコードします.\n",
        "\n",
        "\n",
        "## Loss Function\n",
        "損失関数は（出力, 目標)の入力のペアを受け取り, \n",
        "出力が目標からどれだけ離れているかを推定する値を計算します.\n",
        "``nn``パッケージには, 異なる損失関数が複数実装されています.\n",
        "\n",
        "単純な損失関数は``nn.MSELoss``です. これは入力と目標の間の平均二乗誤差を計算します."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEiTWG0nG-Lf",
        "colab_type": "code",
        "outputId": "788dbff0-8922-4c5f-c96d-fda6d431e37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "out = net(input)\n",
        "target = torch.randn(10)\n",
        "target = target.view(1, -1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(out, target)\n",
        "print(loss)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0076, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU_uF2iL6Z9i",
        "colab_type": "code",
        "outputId": "13a75379-663a-4b06-f61c-7a28bd6f1012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(loss.grad_fn)\n",
        "print(loss.grad_fn.next_functions[0][0])\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7fbdd48c2cf8>\n",
            "<AddmmBackward object at 0x7fbdd48c2dd8>\n",
            "<AccumulateGrad object at 0x7fbdd48c2cf8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juI253PC67e0",
        "colab_type": "text"
      },
      "source": [
        "# Backprop\n",
        "誤差逆伝搬するためには`loss.backward()`を実行するだけです.\n",
        "この時, 既存の勾配情報に新たな情報を蓄積しないために, 既存の勾配情報を初期化しておく必要があります.\n",
        "\n",
        "ここでは, `loss.backward()`を呼び出して, 逆伝搬の前後でconv1s の勾配を見ることにします."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWmHS-t7WYn",
        "colab_type": "code",
        "outputId": "4876e279-07b9-4947-cfc4-e797ae871d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "net.zero_grad()\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "tensor([0., 0., 0., 0., 0., 0.])\n",
            "conv1.bias.grad after backward\n",
            "tensor([-0.0086, -0.0079,  0.0199, -0.0061, -0.0107, -0.0025])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8KgLxjX7n2k",
        "colab_type": "text"
      },
      "source": [
        "## Update the weights\n",
        "実際に使用されている最も単純な最適化関数は確率的勾配降下法(Stochastic Gradient Descent: SGD)です.\n",
        "\n",
        "```\n",
        "    weight = weight - learning_rate * gradient\n",
        "```\n",
        "SGDはPythonを使って以下のように実装できます."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTWnMhOa8E47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(f.grad.data * learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQmKj84QIOWa",
        "colab_type": "text"
      },
      "source": [
        "しかし、ニューラルネットワークを使用すると, SGD, Nesterov-SGD, Adam, RMSPropなど, さまざまな最適化関数を使用したくなります.\n",
        "これを可能にするために, これらの最適化関数を実装した`torch.optim`があります. この使い方はとても簡単で以下の通りです."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIcS1njm8MzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# in your training loop:\n",
        "optimizer.zero_grad()\n",
        "output = net(input)\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}